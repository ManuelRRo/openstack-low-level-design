
 # ejcutar desde fuera del cluster curl http://IP_DEL_NODO:30080
#  kubectl -n ml-test describe pod torch-deploy-5d846468cc-rld4l describe a pod

apiVersion: v1
kind: Namespace
metadata:
  name: ml-test
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: torch-app
  namespace: ml-test
data:
  app.py: |
    import torch
    import json
    from http.server import BaseHTTPRequestHandler, HTTPServer

    INFO = {
      "torch_version": torch.__version__,
      "cuda_available": torch.cuda.is_available(),
    }
    try:
      if torch.cuda.is_available():
        INFO["cuda_device_count"] = torch.cuda.device_count()
        INFO["cuda_name_0"] = torch.cuda.get_device_name(0)
      # prueba rápida de tensores
      a = torch.randn((100,100), device="cuda" if torch.cuda.is_available() else "cpu")
      b = torch.randn((100,100), device=a.device)
      c = torch.matmul(a,b)
      INFO["tensor_mean"] = float(c.mean().item())
    except Exception as e:
      INFO["init_error"] = str(e)

    class Handler(BaseHTTPRequestHandler):
      def _json(self, code, payload):
        self.send_response(code)
        self.send_header("Content-Type", "application/json")
        self.end_headers()
        self.wfile.write(json.dumps(payload).encode())

      def do_GET(self):
        if self.path == "/health":
          self._json(200, {"status":"ok"})
        else:
          self._json(200, INFO)

    if __name__ == "__main__":
      server = HTTPServer(('0.0.0.0', 8000), Handler)
      print("Serving on :8000")
      server.serve_forever()
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: torch-deploy
  namespace: ml-test
spec:
  replicas: 1
  selector:
    matchLabels:
      app: torch-app
  template:
    metadata:
      labels:
        app: torch-app
    spec:
      containers:
        - name: torch
          # CPU: usa la imagen "cpu". Para GPU, más abajo te dejo un parche.
          image: pytorch/pytorch:2.9.0-cuda12.8-cudnn9-runtime
          imagePullPolicy: IfNotPresent
          command: ["python", "/app/app.py"]
          ports:
            - containerPort: 8000
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 20
          volumeMounts:
            - name: app-code
              mountPath: /app
      volumes:
        - name: app-code
          configMap:
            name: torch-app
---
apiVersion: v1
kind: Service
metadata:
  name: torch-svc
  namespace: ml-test
spec:
  type: NodePort
  selector:
    app: torch-app
  ports:
    - port: 8000
      targetPort: 8000
      nodePort: 30080
